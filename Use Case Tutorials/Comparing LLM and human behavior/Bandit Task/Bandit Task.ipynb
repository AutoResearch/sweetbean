{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Reinforcement Learning\n",
    "\n",
    "Bandit tasks are used to study human reinforcement learning behavior. Here, we will implement a simple two-armed bandit task. We then run the same task on a language model specifically trained on tasks like these ([centaur](https://marcelbinz.github.io/centaur/)) and compare the results.\n",
    "\n",
    "## Two-Armed Bandit Task\n",
    "\n",
    "### Imports"
   ],
   "id": "9b59ed742e18a0f5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sweetbean import Block, Experiment\n",
    "from sweetbean.stimulus import Bandit, Text\n",
    "from sweetbean.variable import (\n",
    "    DataVariable,\n",
    "    FunctionVariable,\n",
    "    SharedVariable,\n",
    "    SideEffect,\n",
    "    TimelineVariable,\n",
    ")"
   ],
   "id": "465d8af802c206ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Timeline\n",
    "\n",
    "Here, we slowly change the values of `bandit_1` 10 to 0 and for `bandit_2` in reverse order from 0 to 10.\n"
   ],
   "id": "838416866ba97dbd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "timeline = []\n",
    "for i in range(11):\n",
    "    timeline.append(\n",
    "        {\n",
    "            \"bandit_1\": {\"color\": \"orange\", \"value\": 10 - i},\n",
    "            \"bandit_2\": {\"color\": \"blue\", \"value\": i},\n",
    "        }\n",
    "    )"
   ],
   "id": "98d345f996176fad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Implementation\n",
    "\n",
    "We also keep track of the score with a shared variable to present it between the bandit tasks."
   ],
   "id": "3496e0ca5f0ee9ce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "bandit_1 = TimelineVariable(\"bandit_1\")\n",
    "bandit_2 = TimelineVariable(\"bandit_2\")\n",
    "\n",
    "score = SharedVariable(\"score\", 0)\n",
    "value = DataVariable(\"value\", 0)\n",
    "\n",
    "update_score = FunctionVariable(\n",
    "    \"update_score\", lambda sc, val: sc + val, [score, value]\n",
    ")\n",
    "\n",
    "update_score_side_effect = SideEffect(score, update_score)\n",
    "\n",
    "bandit_task = Bandit(\n",
    "    bandits=[bandit_1, bandit_2],\n",
    "    side_effects=[update_score_side_effect],\n",
    ")\n",
    "\n",
    "score_text = FunctionVariable(\"score_text\", lambda sc: f\"Score: {sc}\", [score])\n",
    "\n",
    "show_score = Text(duration=2000, text=score_text)\n",
    "\n",
    "trial_sequence = Block([bandit_task, show_score], timeline=timeline)\n",
    "experiment = Experiment([trial_sequence])"
   ],
   "id": "6a1ada08dec8c348",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Export the experiment to a html file and run it in the browser.",
   "id": "65ae4706ed556de1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "experiment.to_html(\"bandit.html\", path_local_download=\"bandit.json\")",
   "id": "80fbd261e9ae251a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Results\n",
    "After running bandit.html, there should be a file called `bandit.json` in the download directory. You can open the file in your browser to see the results. First, we process it so that it only contains relevant data:"
   ],
   "id": "94f8c0dff2ef6200"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "from sweetbean.data import process_js, get_n_responses, until_response\n",
    "\n",
    "with open(\"bandit.json\") as f:\n",
    "    data_raw = json.load(f)\n",
    "    \n",
    "data = process_js(data_raw)"
   ],
   "id": "55d66aac9b404c84",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "d41ef6e70a2174c5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can now get the number of times a response was made and get the data until before the third response:",
   "id": "b1332cb3777464bf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "n_responses = get_n_responses(data)\n",
    "data_third_response = until_response(data, 3)"
   ],
   "id": "89f6f6a3996ac454",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Experiment on language model\n",
    "\n",
    "With the partial data, we can now run the experiment up to that point and then run the rest of the experiment on language input. To test this, we run it manually:"
   ],
   "id": "e7d854441716de90"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_input, _ = experiment.run_on_language(input, data=data_third_response)",
   "id": "df2b43db78303c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(data_input)",
   "id": "9619a73c6f650c7e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Instead of running the experiment manually, we can also use a large language model. In this case, we use [centaur](https://marcelbinz.github.io/centaur/). This model has been trained on similar tasks as the two-armed bandit task. We can use the model to predict the next response and then run the experiment on the model. We can then compare the results with the actual data.\n",
    "\n",
    "First, we need to install unsloth"
   ],
   "id": "b6bd38c2dac7d005"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install unsloth \"xformers==0.0.28.post2\"",
   "id": "adfc6886e8c95521",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Then, we load the model:",
   "id": "9fbc588d2d05b244"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import transformers\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "  model_name = \"marcelbinz/Llama-3.1-Centaur-8B-adapter\",\n",
    "  max_seq_length = 32768,\n",
    "  dtype = None,\n",
    "  load_in_4bit = True,\n",
    ")\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "pipe = transformers.pipeline(\n",
    "            \"text-generation\",\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            trust_remote_code=True,\n",
    "            pad_token_id=0,\n",
    "            do_sample=True,\n",
    "            temperature=1.0,\n",
    "            max_new_tokens=1,\n",
    ")"
   ],
   "id": "3ee1c13304ed4c58",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Finally, we create a function to pass into the experiment:",
   "id": "b254acc66b742707"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def generate(prompt):\n",
    "    return pipe(prompt)[0]['generated_text'][len(prompt):]"
   ],
   "id": "8690a65d182324f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can use this to run the full experiment:",
   "id": "e0a02d78fb442cc4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_centaur_full = experiment.run_on_language(generate)",
   "id": "788d66890f32c460",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Or we can run the experiment from the third response",
   "id": "844e2d2f7d3227f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_centaur_partial = experiment.run_on_language(generate, data=data_third_response)\n",
    "\n",
    "# Print the data:\n",
    "print(data_centaur_full)\n",
    "print(data_centaur_partial)\n",
    "print(data)"
   ],
   "id": "fab14fd27f8fae83",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Comparison\n",
    "\n",
    "We can compare the results of the actual data with the data from the language model. For example, we can compare the number overall scores reached by humans and the language model:"
   ],
   "id": "ecabe495aa5f823c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "score_human = sum([d[\"value\"] for d in data])\n",
    "score_centaur = sum([d[\"value\"] for d in data_centaur_full])\n",
    "\n",
    "print(f\"Score human: {score_human}\")\n",
    "print(f\"Score centaur: {score_centaur}\")"
   ],
   "id": "bfcb2e250372c874"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Conclusion\n",
    "\n",
    "This notebook demonstrates how to run a simple bandit task via a website or a language model. The results can, for example, be compared to analyse the language model or can be used in fine-tuning the model.\n",
    "\n",
    "SweetBean is also integrated in [AutoRa](https://autoresearch.github.io/autora/), a platform for running the same experiments automatically via prolific. This allows for automatic data collection and analysis while using large language models either for prototyping, in finding good experimental design or for automatic fine-tuning."
   ],
   "id": "259f633781be66ec"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
